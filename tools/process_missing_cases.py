#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å•ç‹¬å¤„ç†ç¼ºå¤±çš„3ä¸ªCHD case
"""

import os
import sys
import glob
import subprocess
import shutil
from pathlib import Path

def process_missing_cases():
    """å¤„ç†ç¼ºå¤±çš„3ä¸ªcase"""
    
    print("ğŸ”§ å¤„ç†ç¼ºå¤±çš„CHD case")
    print("=" * 50)
    
    # è·¯å¾„é…ç½®
    input_base = r"E:\images\CHD\ç¬¬ä¸€æ¬¡"
    output_base = r"D:\Coronary Database\images\CHD\ç¬¬ä¸€æ¬¡\CHD nii.gz"
    
    # ç¼ºå¤±çš„3ä¸ªcase
    missing_cases = [
        'dicom_5527999',
        'dicom_7013792', 
        'dicom_7275907'
    ]
    
    print(f"ğŸ“¥ è¾“å…¥è·¯å¾„: {input_base}")
    print(f"ğŸ“¤ è¾“å‡ºè·¯å¾„: {output_base}")
    print(f"ğŸ¯ å¾…å¤„ç†case: {len(missing_cases)}ä¸ª")
    
    # æ£€æŸ¥è·¯å¾„
    if not os.path.exists(input_base):
        print(f"âŒ è¾“å…¥è·¯å¾„ä¸å­˜åœ¨: {input_base}")
        return False
        
    if not os.path.exists(output_base):
        print(f"âŒ è¾“å‡ºè·¯å¾„ä¸å­˜åœ¨: {output_base}")
        return False
    
    # æ£€æŸ¥dcm2niixå·¥å…·
    dcm2niix_paths = [
        os.path.join(os.path.dirname(__file__), "..", "tools", "MRIcroGL", "Resources", "dcm2niix.exe"),
        os.path.join(os.path.dirname(__file__), "..", "dcm2niix.exe"),
        "dcm2niix.exe"
    ]
    
    dcm2niix_path = None
    for path in dcm2niix_paths:
        if os.path.exists(path):
            dcm2niix_path = path
            break
    
    if not dcm2niix_path:
        print("âŒ æ‰¾ä¸åˆ°dcm2niix.exeå·¥å…·")
        return False
    
    print(f"ğŸ”§ ä½¿ç”¨dcm2niix: {dcm2niix_path}")
    
    # å¤„ç†æ¯ä¸ªç¼ºå¤±çš„case
    success_count = 0
    failed_cases = []
    
    for i, case_name in enumerate(missing_cases, 1):
        print(f"\nğŸ”„ å¤„ç† {i}/{len(missing_cases)}: {case_name}")
        
        case_path = os.path.join(input_base, case_name)
        
        # æ£€æŸ¥caseç›®å½•æ˜¯å¦å­˜åœ¨
        if not os.path.exists(case_path):
            print(f"  âŒ Caseç›®å½•ä¸å­˜åœ¨: {case_path}")
            failed_cases.append(case_name)
            continue
        
        # ç»Ÿè®¡DICOMæ–‡ä»¶
        dicom_files = []
        for pattern in ['*.dcm', '*.DCM', '*.dicom', '*.ima']:
            dicom_files.extend(glob.glob(os.path.join(case_path, '**', pattern), recursive=True))
        
        # æ£€æŸ¥æ— æ‰©å±•åæ–‡ä»¶
        for root, dirs, files in os.walk(case_path):
            for file in files:
                if not os.path.splitext(file)[1] and file.lower() != 'dicomdir':
                    file_path = os.path.join(root, file)
                    try:
                        # ç®€å•æ£€æŸ¥æ˜¯å¦å¯èƒ½æ˜¯DICOMæ–‡ä»¶
                        with open(file_path, 'rb') as f:
                            header = f.read(132)
                            if b'DICM' in header:
                                dicom_files.append(file_path)
                    except:
                        pass
        
        print(f"  ğŸ“ å‘ç°DICOMæ–‡ä»¶: {len(dicom_files)}ä¸ª")
        
        if len(dicom_files) == 0:
            print(f"  âš ï¸  æœªå‘ç°DICOMæ–‡ä»¶ï¼Œè·³è¿‡")
            failed_cases.append(case_name)
            continue
        
        # æ‰¾åˆ°æœ€å¤§åºåˆ—ï¼ˆæŒ‰ç›®å½•åˆ†ç»„ï¼‰
        series_dict = {}
        for dicom_file in dicom_files:
            series_dir = os.path.dirname(dicom_file)
            if series_dir not in series_dict:
                series_dict[series_dir] = []
            series_dict[series_dir].append(dicom_file)
        
        # é€‰æ‹©æ–‡ä»¶æ•°æœ€å¤šçš„åºåˆ—
        max_series_dir = max(series_dict.keys(), key=lambda x: len(series_dict[x]))
        max_files_count = len(series_dict[max_series_dir])
        
        print(f"  ğŸ¯ é€‰æ‹©æœ€å¤§åºåˆ—: {max_files_count}ä¸ªæ–‡ä»¶")
        print(f"     è·¯å¾„: {os.path.relpath(max_series_dir, case_path)}")
        
        # ä½¿ç”¨dcm2niixè½¬æ¢
        output_filename = f"{case_name}.nii.gz"
        output_filepath = os.path.join(output_base, output_filename)
        
        # æ„å»ºdcm2niixå‘½ä»¤
        cmd = [
            dcm2niix_path,
            '-z', 'y',  # å‹ç¼©è¾“å‡º
            '-f', case_name,  # è¾“å‡ºæ–‡ä»¶å
            '-o', output_base,  # è¾“å‡ºç›®å½•
            max_series_dir  # è¾“å…¥ç›®å½•
        ]
        
        try:
            print(f"  ğŸš€ æ‰§è¡Œè½¬æ¢...")
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=120)
            
            if result.returncode == 0:
                # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶æ˜¯å¦ç”Ÿæˆ
                if os.path.exists(output_filepath):
                    file_size = os.path.getsize(output_filepath) / (1024*1024)  # MB
                    print(f"  âœ… è½¬æ¢æˆåŠŸ: {output_filename} ({file_size:.1f}MB)")
                    success_count += 1
                else:
                    print(f"  âŒ è½¬æ¢å¤±è´¥: è¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨")
                    failed_cases.append(case_name)
            else:
                print(f"  âŒ dcm2niixæ‰§è¡Œå¤±è´¥")
                print(f"     é”™è¯¯: {result.stderr}")
                failed_cases.append(case_name)
                
        except subprocess.TimeoutExpired:
            print(f"  âŒ è½¬æ¢è¶…æ—¶")
            failed_cases.append(case_name)
        except Exception as e:
            print(f"  âŒ è½¬æ¢å¼‚å¸¸: {e}")
            failed_cases.append(case_name)
    
    # å¤„ç†ç»“æœæ€»ç»“
    print(f"\nğŸ“Š å¤„ç†ç»“æœæ€»ç»“")
    print("=" * 30)
    print(f"âœ… æˆåŠŸå¤„ç†: {success_count}ä¸ª")
    print(f"âŒ å¤„ç†å¤±è´¥: {len(failed_cases)}ä¸ª")
    
    if failed_cases:
        print(f"\nå¤±è´¥çš„case:")
        for case in failed_cases:
            print(f"  - {case}")
    
    # æ›´æ–°å…ƒæ•°æ®ï¼ˆå¦‚æœæˆåŠŸå¤„ç†äº†ä»»ä½•caseï¼‰
    if success_count > 0:
        print(f"\nğŸ“‹ æ›´æ–°å…ƒæ•°æ®æ–‡ä»¶...")
        update_metadata(input_base, output_base, missing_cases, failed_cases)
    
    return success_count > 0

def update_metadata(input_base, output_base, processed_cases, failed_cases):
    """æ›´æ–°å…ƒæ•°æ®CSVæ–‡ä»¶"""
    try:
        import pandas as pd
        import pydicom
        from datetime import datetime
        
        # æˆåŠŸå¤„ç†çš„case
        success_cases = [case for case in processed_cases if case not in failed_cases]
        
        if not success_cases:
            print("  âš ï¸  æ²¡æœ‰æˆåŠŸçš„caseéœ€è¦æ›´æ–°å…ƒæ•°æ®")
            return
        
        # è¯»å–ç°æœ‰çš„å…ƒæ•°æ®æ–‡ä»¶
        csv_path = os.path.join(output_base, "case_metadata.csv")
        csv_masked_path = os.path.join(output_base, "case_metadata_masked.csv")
        
        new_records = []
        new_records_masked = []
        
        # è·å–ä¸‹ä¸€ä¸ªProjectID
        next_project_id = 1
        if os.path.exists(csv_path):
            try:
                existing_df = pd.read_csv(csv_path, encoding='utf-8-sig')
                if len(existing_df) > 0:
                    next_project_id = existing_df['ProjectID'].max() + 1
            except:
                pass
        
        # ä¸ºæ¯ä¸ªæˆåŠŸçš„caseæå–å…ƒæ•°æ®
        for case_name in success_cases:
            print(f"  ğŸ“ æå– {case_name} çš„å…ƒæ•°æ®...")
            
            case_path = os.path.join(input_base, case_name)
            
            # æŸ¥æ‰¾DICOMæ–‡ä»¶æ¥æå–å…ƒæ•°æ®
            dicom_files = []
            for pattern in ['*.dcm', '*.DCM', '*.dicom', '*.ima']:
                dicom_files.extend(glob.glob(os.path.join(case_path, '**', pattern), recursive=True))
            
            if not dicom_files:
                continue
            
            # å°è¯•è¯»å–ç¬¬ä¸€ä¸ªDICOMæ–‡ä»¶çš„å…ƒæ•°æ®
            metadata = None
            for dicom_file in dicom_files[:3]:  # å°è¯•å‰3ä¸ªæ–‡ä»¶
                try:
                    ds = pydicom.dcmread(dicom_file, stop_before_pixels=True)
                    
                    # æå–åŸºæœ¬ä¿¡æ¯
                    metadata = {
                        'ProjectID': next_project_id,
                        'FileName': case_name,
                        'PatientName': str(getattr(ds, 'PatientName', '')),
                        'PatientID': str(getattr(ds, 'PatientID', '')),
                        'StudyDate': str(getattr(ds, 'StudyDate', '')),
                        'PatientBirthDate': str(getattr(ds, 'PatientBirthDate', '')),
                        'PatientAge': str(getattr(ds, 'PatientAge', '')),
                        'PatientSex': str(getattr(ds, 'PatientSex', '')),
                        'StudyInstanceUID': str(getattr(ds, 'StudyInstanceUID', '')),
                        'SeriesInstanceUID': str(getattr(ds, 'SeriesInstanceUID', '')),
                        'Modality': str(getattr(ds, 'Modality', '')),
                        'Manufacturer': str(getattr(ds, 'Manufacturer', '')),
                        'Rows': getattr(ds, 'Rows', 0),
                        'Columns': getattr(ds, 'Columns', 0),
                        'ImageCount': len(dicom_files),
                        'SeriesCount': 1  # ç®€åŒ–å¤„ç†
                    }
                    break
                except Exception as e:
                    continue
            
            if metadata:
                new_records.append(metadata)
                
                # åˆ›å»ºè„±æ•ç‰ˆæœ¬
                masked_metadata = metadata.copy()
                patient_name = metadata['PatientName']
                if patient_name and len(patient_name) > 0:
                    if any(ord(c) > 127 for c in patient_name):  # ä¸­æ–‡
                        masked_metadata['PatientName'] = patient_name[0] + '**'
                    else:  # è‹±æ–‡
                        masked_metadata['PatientName'] = patient_name[0] + '**'
                
                new_records_masked.append(masked_metadata)
                next_project_id += 1
        
        # è¿½åŠ åˆ°ç°æœ‰CSVæ–‡ä»¶
        if new_records:
            new_df = pd.DataFrame(new_records)
            new_df_masked = pd.DataFrame(new_records_masked)
            
            # è¿½åŠ åˆ°åŸå§‹æ–‡ä»¶
            if os.path.exists(csv_path):
                existing_df = pd.read_csv(csv_path, encoding='utf-8-sig')
                combined_df = pd.concat([existing_df, new_df], ignore_index=True)
            else:
                combined_df = new_df
            
            combined_df.to_csv(csv_path, index=False, encoding='utf-8-sig')
            
            # è¿½åŠ åˆ°è„±æ•æ–‡ä»¶
            if os.path.exists(csv_masked_path):
                existing_df_masked = pd.read_csv(csv_masked_path, encoding='utf-8-sig')
                combined_df_masked = pd.concat([existing_df_masked, new_df_masked], ignore_index=True)
            else:
                combined_df_masked = new_df_masked
            
            combined_df_masked.to_csv(csv_masked_path, index=False, encoding='utf-8-sig')
            
            print(f"  âœ… å·²æ›´æ–°å…ƒæ•°æ®æ–‡ä»¶ï¼Œæ–°å¢ {len(new_records)} æ¡è®°å½•")
        
    except ImportError:
        print("  âš ï¸  ç¼ºå°‘pandasæˆ–pydicomï¼Œè·³è¿‡å…ƒæ•°æ®æ›´æ–°")
    except Exception as e:
        print(f"  âŒ å…ƒæ•°æ®æ›´æ–°å¤±è´¥: {e}")

if __name__ == "__main__":
    print("ğŸ¯ å¤„ç†ç¼ºå¤±çš„CHD case")
    print("=" * 50)
    
    # ç¡®è®¤å¤„ç†
    response = input("ç¡®è®¤å¤„ç†ç¼ºå¤±çš„3ä¸ªcaseï¼Ÿ(y/N): ").strip().lower()
    if response != 'y':
        print("âŒ å¤„ç†å·²å–æ¶ˆ")
        sys.exit()
    
    success = process_missing_cases()
    
    if success:
        print("\nğŸ‰ å¤„ç†å®Œæˆï¼")
        print("ç°åœ¨æ‚¨åº”è¯¥æœ‰å®Œæ•´çš„62ä¸ªNIfTIæ–‡ä»¶äº†ã€‚")
    else:
        print("\nğŸ˜ å¤„ç†æœªå®Œå…¨æˆåŠŸï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯ã€‚")